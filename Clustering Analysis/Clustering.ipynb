{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Energy Profiles clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import os\n",
    "import time\n",
    "from math import log2\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# NumPy, SciPy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read clustering result file to generate various plots \n",
    "\n",
    "* this file contains daily profiles, clustering assignment, and metadata \n",
    "* this section below reads the profiles generated in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangxiya/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (1,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "combined_profiles = pd.read_csv('final_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate residential and non-residential buildings\n",
    "is_residential = combined_profiles.Industry == 'Residential'\n",
    "residential_profiles = combined_profiles.loc[is_residential, :]\n",
    "non_residential_profiles = combined_profiles.loc[~is_residential, :]\n",
    "\n",
    "# reset index\n",
    "residential_profiles.reset_index(inplace = True, drop = True)\n",
    "non_residential_profiles.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot saving functions\n",
    "\n",
    "* Since we have multipe plots from this analysis, we generate a saving function for handling all these plots\n",
    "* We describe different types of plot as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot - type 1. The first plots are basic exploratory data analysis \n",
    "* 1.1 All the profiles (or samples) with clustering type color coded\n",
    "* 1.2 Averaged profile for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plot_functions.profiles import save_profile_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot - type 2. Clustering analysis by numerical metadata \n",
    "* 2.1 Cluster assignment by sqm\n",
    "* 2.2 Cluster assignment by EUI\n",
    "* 2.3 Cluster assignment by entropy\n",
    "* 2.4 Cluster assignment by day-of-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plot_functions.numerical import save_continuous_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot - type 3. Clustering analysis by categorical metadata \n",
    "* 3.1 Cluster assignment by timezone (region)\n",
    "* 3.2 Cluster assignment by industry\n",
    "* 3.3 Cluster assignment by sub-industry\n",
    "* 3.4 Cluster assignment by primary-space-usage\n",
    "* 3.5 Cluster assignment by date-flag (weekday, weekend, holiday)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot_functions.stacked import save_stacked_bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot - type 4. Entropy distribution analysis \n",
    "* 4.1 Entropy distribution by profiles \n",
    "* 4.2 Entropy distribution by buildings\n",
    "* 4.3 Entropy distribution by cluster assignment\n",
    "\n",
    "* 4~8 categorical metadata\n",
    "* 4.4 Entropy distribution by timezone\n",
    "* 4.5 Entropy distribution by industry\n",
    "* 4.6 Entropy distribution by sub-industry\n",
    "* 4.7 Entropy distribution by primary-space-usage\n",
    "* 4.8 Entropy distribution by date-flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plot_functions.entropy import save_entropy_distribution, save_field_level_entropy_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A complete package for running all the plots with different clustering algorithm\n",
    "\n",
    "* K-means clustering\n",
    "* Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation for profile variation (entropy)\n",
    "* these functions are invoked after each iteration of clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(pd_labels):\n",
    "    result = 0\n",
    "    vals = pd_labels.value_counts()\n",
    "    total = pd_labels.shape[0]\n",
    "    for val in vals:\n",
    "        result -= val/total * log2(val/total)\n",
    "    return result\n",
    "\n",
    "def get_list_of_entropies(profiles):\n",
    "    return profiles.groupby('Building')[['cluster']].transform(calc_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign basic settings for clustering analysis\n",
    "\n",
    "* K-means clustering, and Hierarchical clustering. Testing various clustering numbers (K, from 1 to 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params_list should be a list of dictionaries containing the key-value paris for the input parameters of the models\n",
    "# e.g. KMeans -> {'k' : 3}\n",
    "\n",
    "class ClusteringBaseModel:\n",
    "    def __init__(self, params_list, profiles, cluster_algo, save_dir, labels_dir):\n",
    "        self.algorithms = {\n",
    "            'KMeans': KMeans,\n",
    "            'DBSCAN': DBSCAN,\n",
    "            'AgglomerativeClustering': AgglomerativeClustering,\n",
    "            'GMM': GaussianMixture\n",
    "        }\n",
    "        \n",
    "        self.params_list = params_list\n",
    "        self.profiles = profiles\n",
    "        self.cluster_algo = cluster_algo\n",
    "        self.save_dir = '%s/%s/' % (save_dir, cluster_algo.lower())\n",
    "        self.labels_dir = labels_dir\n",
    "        \n",
    "    def run(self):\n",
    "        for params in self.params_list:\n",
    "            # Fit model with varying k\n",
    "            self.model = self.init_model(params)\n",
    "\n",
    "            if 'params[%s].npy' % urlencode(params) in os.listdir('./%s/%s/' % (self.labels_dir, self.cluster_algo.lower())):\n",
    "                print('Skip model fitting due to saved labels [params: %s]' % (urlencode(params)))\n",
    "                labels = np.load('./%s/%s/params[%s].npy' % (self.labels_dir, self.cluster_algo.lower(), urlencode(params)))\n",
    "            else:\n",
    "                start = time.time()\n",
    "                labels = self.get_labels(self.profiles.iloc[:, 3:3+24])\n",
    "                print('Time spent fitting model: %.4f [params: %s]' % (time.time()-start, urlencode(params)))\n",
    "                np.save('./%s/%s/params[%s].npy' % (self.labels_dir, self.cluster_algo.lower(), urlencode(params)), labels)\n",
    "\n",
    "            self.profiles['cluster'] = labels\n",
    "\n",
    "            # Calculate entropies\n",
    "            start = time.time()\n",
    "            self.profiles['entropy'] = get_list_of_entropies(self.profiles)\n",
    "            print('Time spent on calculating entropies: %fs' % (time.time() - start))\n",
    "\n",
    "            # Generate plots\n",
    "            save_profile_plots(self.cluster_algo, params, self.profiles, self.save_dir)\n",
    "            save_continuous_plots(self.cluster_algo, params, self.profiles, self.save_dir)\n",
    "            save_stacked_bars(self.cluster_algo, params, self.profiles, self.save_dir)\n",
    "            save_entropy_distribution(self.cluster_algo, params, self.profiles, self.save_dir)\n",
    "            save_field_level_entropy_distribution(self.cluster_algo, params, self.profiles, self.save_dir)\n",
    "\n",
    "    # Overwrite this method in the child classes\n",
    "    def init_model(self, params):\n",
    "        raise Exception('Not implemented')\n",
    "\n",
    "    # Overwrite this method in the child classes\n",
    "    def get_labels(self, data):\n",
    "        raise Exception('Not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels_default(model, data):\n",
    "    model.fit(data)\n",
    "    return model.labels_\n",
    "\n",
    "class KmeansClustering(ClusteringBaseModel):\n",
    "    def __init__(self, params_list, profiles, save_dir, labels_dir):\n",
    "        super().__init__(params_list, profiles, 'KMeans', save_dir, labels_dir)\n",
    "    \n",
    "    def init_model(self, params):\n",
    "        return self.algorithms[self.cluster_algo](n_clusters=params['k'])\n",
    "        \n",
    "    def get_labels(self, data):\n",
    "        return get_labels_default(self.model, data)\n",
    "\n",
    "class DBSCANClustering(ClusteringBaseModel):\n",
    "    def __init__(self, params_list, profiles, save_dir, labels_dir):\n",
    "        super().__init__(params_list, profiles, 'DBSCAN', save_dir, labels_dir)\n",
    "\n",
    "    def init_model(self, params):\n",
    "        return self.algorithms[self.cluster_algo](min_samples=params['min_samples'], eps=params['eps'])\n",
    "\n",
    "    def get_labels(self, data):\n",
    "        return get_labels_default(self.model, data)\n",
    "\n",
    "class HierarchicalClustering(ClusteringBaseModel):\n",
    "    def __init__(self, k_range, profiles, save_dir, labels_dir):\n",
    "        super().__init__(k_range, profiles, 'AgglomerativeClustering', save_dir, labels_dir)\n",
    "\n",
    "    def init_model(self, params):\n",
    "        return self.algorithms[self.cluster_algo](n_clusters=params['k'], linkage=params['linkage'])\n",
    "\n",
    "    def get_labels(self, data):\n",
    "        return get_labels_default(self.model, data)\n",
    "\n",
    "class GMMClustering(ClusteringBaseModel):\n",
    "    def __init__(self, k_range, profiles, save_dir, labels_dir):\n",
    "        super().__init__(k_range, profiles, 'GMM', save_dir, labels_dir)\n",
    "\n",
    "    def init_model(self, params):\n",
    "        return self.algorithms[self.cluster_algo](n_components=params['k'])\n",
    "\n",
    "    def get_labels(self, data):\n",
    "        self.model.fit(data)\n",
    "        return self.model.predict(data)\n",
    "\n",
    "class BisectingKMeansClustering(ClusteringBaseModel):\n",
    "    def __init__(self, k_range, profiles, save_dir, labels_dir):\n",
    "        super().__init__(k_range, profiles, 'BisectingKMeans', save_dir, labels_dir)\n",
    "    \n",
    "    # Store params in model\n",
    "    def init_model(self, params):\n",
    "        return params\n",
    "    \n",
    "    def bisect(self, data, index):\n",
    "        model = KMeans(n_clusters=2)\n",
    "        model.fit(data)\n",
    "        return [(data[model.labels_ == 0, :], index[model.labels_ == 0]), (data[model.labels_ == 1, :], index[model.labels_ == 1])]\n",
    "    \n",
    "    def calc_mse(self, data):\n",
    "        mu = np.mean(data, axis=0)\n",
    "        return np.sum((data - mu)**2) / data.shape[0]\n",
    "    \n",
    "    def bisect_k(self, data, k):\n",
    "        data_dict = {}\n",
    "        mse_dict = {}\n",
    "        index_dict = {}\n",
    "        index_array = np.arange(data.shape[0])\n",
    "        final_labels = np.zeros(data.shape[0])\n",
    "        for i in range(k-1):\n",
    "            i1 = i*2\n",
    "            i2 = i*2+1\n",
    "            (data_dict[i1], index_dict[i1]), (data_dict[i2], index_dict[i2]) = self.bisect(data, index_array)\n",
    "            mse_dict[i1] = self.calc_mse(data_dict[i1])\n",
    "            mse_dict[i2] = self.calc_mse(data_dict[i2])\n",
    "\n",
    "            if i < k-2:\n",
    "                max_mse_idx = max(mse_dict.items(), key=lambda x:x[1])[0]\n",
    "                data = data_dict[max_mse_idx]\n",
    "                index_array = index_dict[max_mse_idx]\n",
    "                del mse_dict[max_mse_idx]\n",
    "                del data_dict[max_mse_idx]\n",
    "                del index_dict[max_mse_idx]\n",
    "\n",
    "        # reconstruct labels\n",
    "        cluster_indices_groups = [a[1] for a in sorted(list(index_dict.items()), key=lambda x: x[0])]\n",
    "        cluster_id = 0\n",
    "        for cluster_indices in cluster_indices_groups:\n",
    "            final_labels[cluster_indices] = cluster_id\n",
    "            cluster_id += 1\n",
    "        return final_labels\n",
    "    \n",
    "    def get_labels(self, data):\n",
    "        data = data.as_matrix()\n",
    "        return self.bisect_k(data, self.model['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_params = [{'k': i} for i in range(2,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories = {\n",
    "    'profiles': {\n",
    "        'save_dir': 'final_plots',\n",
    "        'labels_dir': 'final_labels'\n",
    "    },\n",
    "    'residential_profiles': {\n",
    "        'save_dir': 'residential_plots',\n",
    "        'labels_dir': 'residential_labels'\n",
    "    },\n",
    "    'non_residential_profiles': {\n",
    "        'save_dir': 'non_residential_plots',\n",
    "        'labels_dir': 'non_residential_labels'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_save_dir(name):\n",
    "    return directories[name]['save_dir']\n",
    "\n",
    "def get_labels_dir(name):\n",
    "    return directories[name]['labels_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dset_map = {\n",
    "    'profiles': combined_profiles,\n",
    "    'residential_profiles': residential_profiles,\n",
    "    'non_residential_profiles': non_residential_profiles\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dset_name in dset_map:\n",
    "    profiles = dset_map[dset_name]\n",
    "    \n",
    "    kmeansClustering = KmeansClustering(k_params, profiles, get_save_dir(dset_name), get_labels_dir(dset_name))\n",
    "    kmeansClustering.run()\n",
    "    \n",
    "    bisectingKmeansClustering = BisectingKMeansClustering(k_params, profiles, get_save_dir(dset_name), get_labels_dir(dset_name))\n",
    "    bisectingKmeansClustering.run()\n",
    "    \n",
    "    gmmClustering = GMMClustering(k_params, profiles, get_save_dir(dset_name), get_labels_dir(dset_name))\n",
    "    gmmClustering.run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
