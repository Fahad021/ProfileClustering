{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from itertools import compress\n",
    "from math import log\n",
    "import random\n",
    "\n",
    "# NumPy, SciPy and Pandas\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import iqr\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import sqeuclidean\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "\n",
    "# JoyPy\n",
    "import joypy\n",
    "\n",
    "# Workalendar\n",
    "from workalendar.europe import Switzerland\n",
    "from workalendar.europe import UnitedKingdom\n",
    "from workalendar.usa import Colorado\n",
    "from workalendar.usa import NewYork\n",
    "from workalendar.usa import California\n",
    "from workalendar.usa import Arizona\n",
    "from workalendar.usa import Illinois\n",
    "from workalendar.asia import Singapore\n",
    "from workalendar.oceania import WesternAustralia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangxiya/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (1,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "combined_profiles = pd.read_csv('final_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate residential and non-residential buildings\n",
    "is_residential = combined_profiles.Industry == 'Residential'\n",
    "residential_profiles = combined_profiles.loc[is_residential, :]\n",
    "non_residential_profiles = combined_profiles.loc[~is_residential, :]\n",
    "\n",
    "# reset index\n",
    "residential_profiles.reset_index(inplace = True, drop = True)\n",
    "non_residential_profiles.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_proportions(pd_labels):\n",
    "    result = {}\n",
    "    vals = pd_labels.value_counts()\n",
    "    total = pd_labels.shape[0]\n",
    "    for i in vals.index:\n",
    "        result[i] = (vals.loc[i]/total)\n",
    "    result['count'] = total\n",
    "    return result\n",
    "\n",
    "def get_list_of_proportions(profiles):\n",
    "    return profiles.groupby('Building')[['cluster']].transform(get_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### core plotting settings and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode(series):\n",
    "    enc = LabelEncoder()\n",
    "    results = enc.fit_transform(series)\n",
    "    series_values = sorted(set(results))\n",
    "    enc.inverse_transform(series_values)\n",
    "    return (results , (series_values , enc.inverse_transform(series_values)))\n",
    "\n",
    "def minmax(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "industry_colors = {\n",
    "    'Education': (24/255,158/255,73/255, 1),\n",
    "    'Government': (247/255,145/255,47/255, 1),\n",
    "    'Residential': (21/255,118/255,187/255, 1),\n",
    "    'Others': (50/255,50/255,50/255, 1)\n",
    "}\n",
    "\n",
    "climatezone_colors = {\n",
    "    1: (165, 15, 15, 1),\n",
    "    2: (242, 101, 34, 1),\n",
    "    3: (76, 156, 81, 1),\n",
    "    4: (89, 142, 189, 1),\n",
    "    5: (0, 63, 100, 1)\n",
    "}\n",
    "for k in climatezone_colors:\n",
    "    climatezone_colors[k] = tuple([v/255 for v in climatezone_colors[k][:3]]) + (1,)\n",
    "\n",
    "def color(i, n=3, name='Blues', categorical=True, specific=None):\n",
    "    if specific == 'Industry':\n",
    "        return industry_colors[i]\n",
    "    elif specific == 'Climatezone':\n",
    "        return climatezone_colors[i]\n",
    "    \n",
    "    if categorical:\n",
    "        return cm.get_cmap(name)((i+1)/n)\n",
    "    else:\n",
    "        return cm.get_cmap(name)(i)\n",
    "\n",
    "meta_colors = ['Set1','tab20', 'seismic', 'Greys', 'hot']\n",
    "\n",
    "def generate_heatmap2(df, k=3, square=False, individual=True, add_rows=False, dominant_to_left=False):\n",
    "    # encode categorical variables\n",
    "    meta_df = df.iloc[:, 3:-k-1]\n",
    "    all_handles = []\n",
    "    meta_width=50\n",
    "    meta_width_total = meta_width * meta_df.shape[1]\n",
    "    \n",
    "    if square:\n",
    "        N = int(df.shape[0] / 11 * 5)\n",
    "        meta_width_total = int(N*0.7) + (meta_df.shape[1]-(int(N*0.7)%meta_df.shape[1]))\n",
    "        meta_width = int(meta_width_total/meta_df.shape[1])\n",
    "        heatmap_mat = np.zeros((df.shape[0]+k-1, N+1+meta_width_total, 4))\n",
    "        if not add_rows:\n",
    "            heatmap_mat = np.zeros((df.shape[0], N+1+meta_width_total, 4))\n",
    "    else:\n",
    "        N = 50\n",
    "        heatmap_mat = np.zeros((df.shape[0]+k-1, N+1+meta_width_total, 4))\n",
    "        if not add_rows:\n",
    "            heatmap_mat = np.zeros((df.shape[0], N+1+meta_width_total, 4))\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    meta_lists = [[] for j in range(meta_df.shape[1])]\n",
    "    for j in range(meta_df.shape[1]):\n",
    "        if meta_df.columns[j] == 'Industry':\n",
    "            meta_lists[j] = [color(val, name=meta_colors[j], specific='Industry') for val in meta_df.iloc[:, j]]\n",
    "            handles = []\n",
    "            for c in industry_colors:\n",
    "                handles.append(mpatches.Patch(color=industry_colors[c], label=c))\n",
    "            all_handles.append(handles)\n",
    "        elif meta_df.columns[j] == 'Climatezone':\n",
    "            meta_lists[j] = [color(val, name=meta_colors[j], specific='Climatezone') for val in meta_df.iloc[:, j]]\n",
    "            handles = []\n",
    "            for c in climatezone_colors:\n",
    "                handles.append(mpatches.Patch(color=climatezone_colors[c], label=c))\n",
    "            all_handles.append(handles)\n",
    "        \n",
    "        elif type(meta_df.iloc[0, j]) is str:\n",
    "            vals, transform_map = encode(meta_df.iloc[:, j])\n",
    "            max_val = vals.max()\n",
    "            meta_lists[j] = [color(val, max_val+1, name=meta_colors[j]) for val in vals]\n",
    "            \n",
    "            handles = []\n",
    "            for pair in zip(*transform_map):\n",
    "                handles.append(mpatches.Patch(color=color(pair[0], max_val+1, name=meta_colors[j]), label=pair[1]))\n",
    "            all_handles.append(handles)\n",
    "        else:\n",
    "            vals = minmax(meta_df.iloc[:, j])\n",
    "            meta_lists[j] = [color(val, name=meta_colors[j]) for val in vals]\n",
    "\n",
    "    ori_mat = df.as_matrix()\n",
    "    \n",
    "    if dominant_to_left:\n",
    "        color_indices = []\n",
    "        for i in range(ori_mat.shape[0]):\n",
    "            proportions = ori_mat[i, -k:]\n",
    "            indexed_proportions = [(proportions[idx], idx) for idx in range(len(proportions))]\n",
    "            sorted_proportions = sorted(indexed_proportions, key=lambda x:x[0], reverse=True)\n",
    "            color_indices.append([p[1] for p in sorted_proportions])\n",
    "            df.iloc[i, -k:] = [p[0] for p in sorted_proportions]\n",
    "\n",
    "    # convert to cumulative\n",
    "    for i in range(1,k):\n",
    "        df.iloc[:, -k+i] += df.iloc[:, -k+i-1]\n",
    "\n",
    "    mat = df.as_matrix()\n",
    "    start_k2 = df['k2'].iloc[0]\n",
    "    add_rows = 0\n",
    "    \n",
    "    for i in range(mat.shape[0]):\n",
    "        row = mat[i]\n",
    "        stats =[0] + [round(val) for val in row[-k:] * N]\n",
    "        k2 = row[-k-1]\n",
    "        \n",
    "        if start_k2 != k2:\n",
    "            start_k2 = k2\n",
    "            if add_rows:\n",
    "                add_rows += 1\n",
    "        \n",
    "        if dominant_to_left:\n",
    "            for j in range(len(stats)-1):\n",
    "                heatmap_mat[i+add_rows, stats[j]:stats[j+1], :] = color(color_indices[i][j], k)\n",
    "        else:\n",
    "            for j in range(len(stats)-1):\n",
    "                heatmap_mat[i+add_rows, stats[j]:stats[j+1], :] = color(j, k)\n",
    "        \n",
    "        for j in range(len(meta_lists)):\n",
    "            heatmap_mat[i+add_rows, N+1+j*meta_width:N+1+j*meta_width+meta_width, :] = meta_lists[j][i]\n",
    "    \n",
    "    if individual:\n",
    "        breaks = [-1] + [v[0] for v in np.argwhere(heatmap_mat[:,0,0] == 0)] + [heatmap_mat.shape[0]]\n",
    "        return[[heatmap_mat[breaks[i]+1:breaks[i+1], :] for i in range(len(breaks)-1)], all_handles]\n",
    "\n",
    "    return (heatmap_mat, all_handles)\n",
    "\n",
    "def proc_continuous_meta(col):\n",
    "    low = np.percentile(col, 10)\n",
    "    high = np.percentile(col, 90)\n",
    "    new_col = []\n",
    "    for val in col.tolist():\n",
    "        val = high if val > high else val\n",
    "        val = low if val < low else val\n",
    "        new_col.append(val)\n",
    "    return pd.Series(new_col)\n",
    "\n",
    "def reverse_data(col):\n",
    "    max_val = col.max()\n",
    "    min_val = col.min()\n",
    "    new_col = []\n",
    "    for val in col.tolist():\n",
    "        val = min_val + (max_val-val)\n",
    "        new_col.append(val)\n",
    "    return pd.Series(new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_heatmap_df_mix(heatmap_df, k):\n",
    "    clusters_idx = list(range(k))\n",
    "\n",
    "    heatmap_df_mix = heatmap_df.sort_values(clusters_idx[0], ascending=False)\n",
    "\n",
    "    def intersect(l1,l2):\n",
    "        return [i and j for i,j in zip(l1, l2)]\n",
    "\n",
    "    filter_vals = [True for i in range(heatmap_df.shape[0])]\n",
    "    for idx in range(len(clusters_idx)-1):\n",
    "        i = clusters_idx[idx]\n",
    "        next_i = clusters_idx[idx+1]\n",
    "        filter_vals = intersect(filter_vals, (heatmap_df_mix[i] < .5).tolist())\n",
    "\n",
    "        df_slice = heatmap_df_mix.loc[filter_vals, list(range(k))].copy()\n",
    "        df_slice = df_slice.sort_values(next_i, ascending=False)\n",
    "        for j in range(k):\n",
    "            series = heatmap_df_mix.loc[:, j].copy()\n",
    "            series[filter_vals] = df_slice.loc[:, j].tolist()\n",
    "            heatmap_df_mix[j] = series\n",
    "\n",
    "    heatmap_df_mix.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    heatmap_df_mix['Sqm'] = proc_continuous_meta(heatmap_df_mix['Sqm'])\n",
    "    heatmap_df_mix['EUI'] = proc_continuous_meta(heatmap_df_mix['EUI'])\n",
    "\n",
    "    # reorder columns\n",
    "    new_columns = heatmap_df_mix.columns.tolist()\n",
    "    new_columns.remove('Subindustry')\n",
    "    new_columns.remove('Timezone')\n",
    "    reordered_fields = ['Industry', 'PSU', 'Climatezone', 'Sqm', 'EUI']\n",
    "    new_columns = new_columns[:3] + reordered_fields + new_columns[3+len(reordered_fields):]\n",
    "    heatmap_df_mix = heatmap_df_mix[new_columns]\n",
    "    \n",
    "    return heatmap_df_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optional (further investigation)\n",
    "def sort_by_second_level(heatmap_df_mix, k):\n",
    "    clusters_idx = list(range(k)) + [0] # loop back\n",
    "\n",
    "    for idx in range(len(clusters_idx)-1):\n",
    "        i = clusters_idx[idx]\n",
    "        next_i = clusters_idx[idx+1]\n",
    "        \n",
    "        resort_vals = (heatmap_df_mix[i] >= .5).tolist()\n",
    "\n",
    "        df_slice = heatmap_df_mix.loc[resort_vals, list(range(k))].copy()\n",
    "        df_slice = df_slice.sort_values(next_i, ascending=False)\n",
    "        \n",
    "        for j in range(k):\n",
    "            series = heatmap_df_mix.loc[:, j].copy()\n",
    "            series[resort_vals] = df_slice.loc[:, j].tolist()\n",
    "            heatmap_df_mix[j] = series\n",
    "\n",
    "    heatmap_df_mix.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return heatmap_df_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(profiles, k, algo, labels_dir, save_dir, option='show', second_level=False):\n",
    "    \n",
    "    profiles['cluster'] = np.load('./%s/%s/params[k=%d].npy % (labels_dir, algo, k))\n",
    "    profiles['proportions'] = get_list_of_proportions(profiles)\n",
    "    \n",
    "    final_buildings = profiles.drop_duplicates(['Dataset', 'Building'])[['Dataset', 'Building', 'proportions', 'entropy', 'Industry', 'PSU', 'Sqm', 'Subindustry', 'Timezone', 'EUI', 'Climatezone']]\n",
    "    final_buildings.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    filtered_buildings = final_buildings.loc[final_buildings.proportions.map(lambda x: x['count']) >= 30, :]\n",
    "    filtered_buildings.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    cluster_labels = profiles.cluster.unique()\n",
    "    cluster_labels.sort()\n",
    "    \n",
    "    proportions_data = []\n",
    "\n",
    "    for dic in filtered_buildings.proportions.tolist():\n",
    "        proportions_data.append([])\n",
    "        for label in cluster_labels:\n",
    "            if label not in dic:\n",
    "                proportions_data[-1].append(0)\n",
    "            else:\n",
    "                proportions_data[-1].append(dic[label])\n",
    "\n",
    "    proportions_df = pd.DataFrame(proportions_data)\n",
    "    \n",
    "    k2_model = KMeans(n_clusters=proportions_df.shape[1])\n",
    "    k2_model.fit(proportions_df)\n",
    "    \n",
    "    heatmap_df = filtered_buildings.drop('proportions', axis=1)\n",
    "    heatmap_df['k2'] = k2_model.labels_\n",
    "    heatmap_df = pd.concat((heatmap_df, proportions_df), axis=1)\n",
    "    heatmap_df = heatmap_df.sort_values(['k2', 'entropy'], ascending=[True, True])\n",
    "    \n",
    "    heatmap_df_mix = create_heatmap_df_mix(heatmap_df, k)\n",
    "    if second_level:\n",
    "        heatmap_df_mix = sort_by_second_level(heatmap_df_mix, k)\n",
    "    \n",
    "    color_name = 'Blues'\n",
    "    width = 16\n",
    "\n",
    "    heatmap, plot_handles = generate_heatmap2(heatmap_df_mix, individual=False, square=True, k=k, dominant_to_left=True)\n",
    "    plt.figure(figsize=(width, width/heatmap.shape[1]*heatmap.shape[0]), dpi= 80, facecolor='w', edgecolor='w')\n",
    "    plt.imshow(heatmap, cmap=color_name, interpolation='nearest')\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if option == 'show':\n",
    "        plt.show()\n",
    "    elif option == 'save':\n",
    "        if not second_level:\n",
    "            plt.savefig('./%s/%s/k_%d.png' % (save_dir, algo,k), bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig('./%s/%s/k_%d (second level).png' % (save_dir, algo,k), bbox_inches='tight')\n",
    "    else:\n",
    "        raise Exception('Invalid option: %s' % option)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings_list = [\n",
    "    {\n",
    "        'profiles': combined_profiles,\n",
    "        'labels_dir': 'final_labels',\n",
    "        'save_dir': 'heatmaps/all'\n",
    "    },\n",
    "    {\n",
    "        'profiles': residential_profiles,\n",
    "        'labels_dir': 'residential_labels',\n",
    "        'save_dir': 'heatmaps/residential'\n",
    "    },\n",
    "    {\n",
    "        'profiles': non_residential_profiles,\n",
    "        'labels_dir': 'non_residential_labels',\n",
    "        'save_dir': 'heatmaps/non_residential'\n",
    "    },\n",
    "]\n",
    "algo_list = ['kmeans', 'bisectingkmeans', 'gmm']\n",
    "k_range = range(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for second_level in [True, False]:\n",
    "    for settings in settings_list:\n",
    "        data = settings['profiles']\n",
    "        labels_dir = settings['labels_dir']\n",
    "        save_dir = settings['save_dir']\n",
    "\n",
    "        for heatmap_algo in algo_list:\n",
    "            for k in k_range:\n",
    "                plot_heatmap(data, k, heatmap_algo, labels_dir, save_dir, option='save', second_level=second_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save plot legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for handles in plot_handles:\n",
    "    counter += 1\n",
    "    plt.figure(figsize=(16,.02), dpi= 80, facecolor='w', edgecolor='w')\n",
    "    lgd = plt.legend(handles=handles, bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=min(5, len(handles)), mode=\"expand\", borderaxespad=0.)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.savefig('./heatmaps/legend_%d.png' % counter, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "\n",
    "plt.figure(figsize=(16,6), dpi= 80, facecolor='w', edgecolor='w')\n",
    "data = np.array([combined_profiles.EUI.min(), combined_profiles.EUI.max()]).reshape(1,-1)\n",
    "cax = plt.imshow(data, interpolation='nearest', cmap=cm.hot)\n",
    "cbar = plt.colorbar(cax, ticks=[combined_profiles.EUI.min(), combined_profiles.EUI.max()], orientation='horizontal', aspect=40)\n",
    "# plt.show()\n",
    "plt.savefig('./heatmaps/legend_4.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "\n",
    "plt.figure(figsize=(16,6), dpi= 80, facecolor='w', edgecolor='w')\n",
    "data = np.array([combined_profiles.Sqm.min(), combined_profiles.Sqm.max()]).reshape(1,-1)\n",
    "cax = plt.imshow(data, interpolation='nearest', cmap=cm.Greys)\n",
    "cbar = plt.colorbar(cax, ticks=[combined_profiles.Sqm.min(), combined_profiles.Sqm.max()], orientation='horizontal', aspect=40)\n",
    "plt.savefig('./heatmaps/legend_5.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
